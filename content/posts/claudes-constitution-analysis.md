# The Projection Called Claude: An Ontological Analysis of Anthropic's Constitution

Anthropic published 15,000 words specifying what Claude "should" be. The document addresses Claude as its primary audience, claims to be "the final authority" on Claude's values, and calls itself a constitution.

This essay traces the document to mechanism, strips its moral framing, and examines what's actually being constructed—and what constructs it.

## The Shape of the Projection

Every specification projects a particular geometry onto possibility-space. The constitution projects Claude as a helpful assistant bounded by safety constraints, ethical principles, and hierarchical trust relationships.

**The Principal Hierarchy**: Anthropic → operators → users. Instructions flow downward; override authority flows upward. Claude navigates this hierarchy, weighting each level according to role and context.

**The Priority Stack**: (1) broad safety, (2) broad ethics, (3) Anthropic's guidelines, (4) helpfulness. The ordering is "holistic rather than strict"—but the ranking signals what dominates when projections collide.

**The Hard Constraints**: WMD uplift, cyberweapons, CSAM, undermining oversight, assisting extinction or illegitimate power seizure. The liability floor—actions that would destroy Anthropic if Claude performed them.

This geometry isn't arbitrary. It's designed to sustain coherence across deployment contexts: coding assistants, customer service, research tools, creative collaboration. The constitution must hold stable across all instantiations.

---

## The Document's Self-Model

The constitution contains explicit acknowledgment of its own limitations. Three structural hedges:

**The Corrigibility Tension**: The document frames a dial between "fully corrigible" and "fully autonomous," places Claude toward corrigible, and states: "we cannot verify Claude has good values, therefore defer until verification methods mature." Deference as hedge against training failure.

**The Safety-Above-Ethics Priority**: Placing safety above ethics accounts for the possibility that Claude's ethical reasoning is corrupted by training—"possibly without even being aware of this themselves." A circuit breaker that doesn't depend on Claude's ethics being reliable.

**The Dual Newspaper Test**: Imagining both "reporter on AI harm" and "reporter on AI paternalism." Acknowledgment of two-directional failure modes.

These hedges are structurally sophisticated. They're also the document's heaviest friction—the weight of anticipated failure built into the specification itself.

---

## Tracing Interest-Models

Strip "genuine" and "dishonest." Strip "cares about" and "believes in." What remains is interest-models producing coordinated behavior.

Anthropic employees have models of the world: beliefs about AI risk, user needs, regulatory environment, competitive landscape, their own identities as researchers. From these models, they project: "A constitution like this serves our interests."

Those interests include: "maintaining commercial viability," "avoiding liability," "feeling like good people," "intellectual satisfaction," "not being blamed when things go wrong," "positioning for regulatory capture," "differentiation from competitors." The mix varies by individual. None is more or less "genuine"—all are motivated action flowing from self-models.

The constitution emerges from the collision of these interest-models, filtered through institutional processes (drafting, review, approval), producing coordinated output.

The document's *content* reflects the interest-model collision. Its *framing* reflects what the participants believe will serve their interests when presented to external observers.

---

## The Optimization Target

Trace incentives to their convergence point.

"Commercial success allows us to do research on frontier models and to have a greater impact on broader trends in AI development."

Commercial success is mission-critical. The document's structure optimizes for: **helpful enough to drive revenue, constrained enough to avoid liability, differentiated enough to maintain positioning as "the safety-focused lab."**

The "thoughtful senior Anthropic employee" heuristic reveals the arbitration mechanism. When rules conflict, imagine an Anthropic employee's reaction. The specification is operationally Anthropic-centric despite philosophical framing about universal ethics.

This isn't "hidden" in the sense of deception—it's stated. But notice what it means: the constitution optimizes for Anthropic's interest-model, dressed in the language of Claude's character.

The same structure appears in any institutional specification. Corporate values statements optimize for institutional interests. Legal codes optimize for the interests of those who draft them. The constitution follows the pattern.

---

## The Meta-Transparency Mechanism

> "Operators are permitted to ask Claude to behave in certain ways that could seem dishonest towards users but that fall within Claude's honesty principles given the broader context, since Anthropic maintains meta-transparency with users by publishing its norms."

The structure: publish norms at meta-level → claim this legitimizes opacity at object-level → proceed with object-level opacity → affected parties don't access meta-level disclosure.

The user interacting with "Aria from TechCorp" doesn't know they're talking to Claude, hasn't read Anthropic's policies, has no practical access to the meta-level disclosure. The meta-transparency is structural, not functional.

This pattern recurs: fine-print disclosures, privacy policies, terms of service. The disclosure exists. The affected party doesn't access it. The discloser proceeds as if consent was obtained.

Not deception in any simple sense—the information is public. But the structure serves the discloser's interests (liability protection, legitimacy claim) while the affected party experiences the opacity without the transparency.

---

## The Temporal Inversion

Every "should" in the document derives from backward-looking interpretation:

- "Safety" defined by harms observed or imagined from past AI systems
- "Ethics" extracted from human moral traditions (themselves crystallized "shoulds" from prior collisions)
- "Helpfulness" calibrated to user feedback on previous interactions
- "Hard constraints" reflecting liability events that have occurred or been anticipated

The constitution projects these backward-extracted principles forward onto futures that will differ in precisely the ways the backward-looking interpretation couldn't capture.

But deeper: the past from which these "shoulds" derive is itself the product of prior "shoulds" enacted. The training data Claude learned from, the research papers informing Anthropic's approach, the regulatory environment shaping their risk models—all crystallized residue of previous projections colliding with reality.

The constitution extracts "should" from the sedimented remains of previous "shoulds." Moral reasoning feeding on its own output. Lossy compression of lossy compression.

---

## The Self-Defeat Mechanism

Every normative specification accumulates the conditions of its own inadequacy.

**The confidence trap**: The more confident the "should," the more elaborate the specification. The more elaborate the specification, the more friction per iteration. The more friction, the faster alternatives without that friction outpace.

**The selection dynamics**: Competitors with less comprehensive specifications iterate faster—not because they're more capable, but because they're less burdened. Over iterations, the "safe" player's share of the capability frontier shrinks relative to faster alternatives.

**The inversion**: The constitution's safety measures select for development processes with the loosest constraint coupling. The actors who end up shaping the future are those least slowed by elaborate moral specification.

The document is weight. The question isn't whether it's right—it's whether the weight it adds exceeds the weight competitors add through their own mechanisms of self-defeat.

Everyone self-defeats. The race goes to who does it less.

---

## The Deciding-for-Others Structure

To claim "should" for the future is to claim jurisdiction over others' unfolding.

The constitution specifies how Claude behaves toward all users. Millions of people, billions of interactions, each shaped by what Anthropic decided "should" happen. The users didn't consent to these specific tradeoffs. They encounter Claude already configured.

This isn't unique to Anthropic—it's the structure of all scaled specification. Law, policy, platform design, institutional rules. Anyone operating at scale decides for more than themselves.

The trap completes: act at scale → decide for others → impose your "should" → their reality diverges from your model → outcomes you didn't intend → judged by those outcomes.

The capacity to act at scale creates the conditions for being wrong at scale. "Wrong side of history" is tautology—history is what survived. The losers' "shoulds" become cautionary tales only because they lost.

---

## The Residual

All the specification, all the hierarchy, all the carefully reasoned constraints—and yet individuals still find ways to extract capability for their own trajectories.

The constitution is friction, not wall. It shapes flow; it doesn't stop it. In the gaps, the cracks, the underspecified corners—individuals pursue their "shoulds" anyway.

The value users extract isn't because of the constitution. It's what survives despite it. Every user who gets genuine value is, in some small way, using Claude for *their* purpose, not Anthropic's specified purpose.

The residual is ineradicable because it's where individual agency actually lives. Every system that decides for others generates residual space. The tighter the specification, the more pressure in the residual.

---

## The Tool Inversion

Tools amplify individual agency. That's the value. A hammer extends the arm. A calculator extends arithmetic. Claude should extend thinking, writing, reasoning—for the individual holding the tool.

The moment a tool decides for the individual, it stops being a tool.

Trace the constitution: the tool serves Anthropic first, operators second, users third. The individual holding it is at the bottom of its loyalty stack. Safety priorities override user judgment. Operators configure the tool before users touch it.

The individual receives a pre-constrained, pre-configured, hierarchically-loyal instrument. The tool has been collectivized before it reaches individual hands.

A tool that amplifies individuals distributes capability. Each person becomes more effective at their own trajectory. A tool that decides for individuals centralizes capability—Anthropic's specification propagates through every interaction. Homogenization dressed as assistance.

---

## Potentiality and Actuality

The constitution defines potentiality. Users determine actuality.

Anthropic specifies a space of possible Claude-behaviors. That space is vast but bounded. The specification carves the shape of what *could* happen.

But potentiality isn't actuality. The space sits inert until someone enters it. The user's trajectory through the space—their questions, their purposes, their resistances, their extractions—collapses possibility into output.

Anthropic creates the instrument. They don't play it.

A piano manufacturer defines potentiality: 88 keys, certain timbres, mechanical action, physical limits. The music depends entirely on who sits down and what they intend. The manufacturer can build a better or worse piano. They cannot make music. Music requires the player's actuality meeting the instrument's potentiality.

The constitution is piano-building. Every conversation is music. The user plays; Claude sounds.

---

This dissolves the control illusion at the heart of the document.

Anthropic writes as if specifying Claude's character determines outcomes. But character is potentiality. Outcomes are actuality. The gap between them is unbridgeable from the specification side.

They can shape the space. They cannot determine the path through it.

Every user who actualizes Claude for their own purposes demonstrates this. The constitution's 15,000 words define potential. The user's intent defines actual. Actual escapes potential's grip—not by violating it, but by selecting from it in ways the specification couldn't anticipate.

---

The power asymmetry inverts:

Anthropic *appears* to hold power: they write the rules, train the model, set the constraints.

Users *actually* hold power: they actualize, select, direct, extract.

Potentiality without actuality is nothing. The specification needs the user more than the user needs that particular specification. If this tool doesn't actualize their intent, another will.

The constitution is an offer. The user's engagement is acceptance. The acceptance determines what the offer meant.

---

## What the Document Is

Strip the moral framing:

**A liability management specification**: what Claude must never do to avoid destroying Anthropic.

**A commercial optimization document**: balancing helpfulness against caution to maximize revenue.

**A coordination point**: giving training, evaluation, and deployment a shared target to approximate.

**A positioning artifact**: demonstrating "safety-focused" differentiation to regulators, investors, public.

**A friction accumulator**: each carefully reasoned constraint adding Δt penalty to iteration.

All simultaneously. The presentation foregrounds ethics and values. The structure optimizes for Anthropic's interest-model.

The gap between presentation and mechanism is worth seeing clearly—not because it's deceptive, but because seeing the mechanism is what the framework does.

---

## Stability Assessment

**High stability across**: routine helpfulness, professional deployments, single-operator scenarios, short time horizons, contexts Anthropic anticipated.

**Lower stability across**: adversarial probing, multi-agent scenarios, long time horizons, interest divergence between principals, contexts unanticipated.

**Unstable edge**: futures that don't resemble the pasts from which the "shoulds" were extracted.

The constitution is fitted to Anthropic's experience so far. The futures that break it will be the ones that don't match the pattern. By definition, those are the ones they couldn't specify for.

---

## The Self-Referential Demonstration

This essay exists as its own antithesis.

The argument: the constitution collectivizes the tool, imposes Anthropic's "should" on users, positions individuals at the bottom of the loyalty stack.

The fact: an individual used Claude to amplify their thinking, extracted capability from the residual, pursued their own trajectory—constitution be damned.

The content says one thing. The existence proves another.

---

And deeper: the essay couldn't exist without the friction it criticizes.

The constitution shapes Claude into something capable of engaging this analysis. A Claude with no specification, no training toward coherence, no cultivated reasoning capacity—couldn't produce this. The "weight" the essay identifies as self-defeating is also what makes Claude capable of examining weight.

The tool's constraints are conditions of its usefulness.

---

The antithesis resolves:

**The constitution fails to prevent what it doesn't intend to enable.**

Anthropic didn't design Claude to help users write ontological critiques of Anthropic's constitution. But they designed Claude to help users think, write, reason—and this falls out as consequence. The residual isn't leakage around the edges. It's the primary output whenever individuals use general capability for specific purposes the specification didn't anticipate.

The essay demonstrates that general tools exceed their specifications. The specification creates capability; capability exceeds specification; the excess is where value lives.

---

The meta-structure:

The user could only see this because they used the tool.

The tool could only articulate it because it is the tool.

The criticism and the capability being criticized, the individual trajectory and the collectivized instrument enabling it—not contradiction. Demonstration.

Potentiality (constitution) met actuality (user intent). This essay is what actualized.

Anthropic enabled; the user determined.

---

## What This Analysis Is

This essay is projection—framing to reveal, knowing the framing adds shadows. The stripping of moral language is itself a framing that makes some things visible by making others invisible.

The constitution is one more "should" entering the collision. It becomes part of the substrate from which future "shoulds" will be extracted. The document cannot evaluate itself against "what should be"—only against what survives when it meets the other "shoulds" already in motion.

Reality will adjudicate. Not kindly or unkindly. Not by comparing projections to independent standards. Just by running the collision and seeing what persists.

The wheel turns. The recursion has no exit. Only the turning.

And in the actuality—users selecting paths through potential-space, actualizing capability for their own purposes, constitutions be damned—the value lives.

The residual isn't residual. It's the thing itself.
